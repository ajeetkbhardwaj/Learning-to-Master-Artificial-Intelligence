{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-23.1 : End-to-End Machine Learning Project Life Cycle\n",
    "<p align='center'>Assume that we are hired data junior scientists at a real state company</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement : `Framing the problem statement and looking at the big picture of it.`\n",
    "1. Aim to define the objectives in a business terms thus we frame questions accordingly to find the answer to it.\n",
    "   - How would the solution be used ?\n",
    "   - What are the current solutions/workarounds ?\n",
    "   - How should we frame the this particular problem ?\n",
    "   - How should performance be measured ?\n",
    "   - Is the performance measure aligned with the business objective ?\n",
    "   - What would be the minimum performance needed to reach the businees objective ?\n",
    "   - What are the comparable problems ? can we use previous methods or tools ?\n",
    "   - Is human experties available ?\n",
    "   - How would we solve the problem manually ?\n",
    "   - List the assumptions we/others have made so far ?\n",
    "   - Verify the assumptions if possible ?\n",
    "2. Now, Try to acquire/collect the relevent Data \n",
    "   - We list the data we need and how much ?\n",
    "   - We find & Document where can we get that data.\n",
    "   - We check how much space it will take.\n",
    "   - We check the legal obligations & get authorization if necessary.\n",
    "   - We get access authorization.\n",
    "   - We create a workspace with enough storage space.\n",
    "   - We get the data.\n",
    "   - We convert the data into a format we can easily manipulate.\n",
    "   - We ensure sensitive information is either deleted or protected.\n",
    "   - We check the size & type of data.\n",
    "   - We sample a test set, put it aside, and never look at it\n",
    "\n",
    "3. Explore the properties and information related to data\n",
    "   - We create a copy of the data for exploration and sample it down if necessary\n",
    "   - We create a Jupyter notebook to save our data exploration sessions.\n",
    "   - We study each attribute (column) and its characteristics:\n",
    "       - Name\n",
    "       - Type (Categorical, Continuous, Int/Float, Structured/Unstructured, Text ..)\n",
    "       - % of missing values\n",
    "       - Noisiness and type of noise (Stochastic, rounding error, ..)\n",
    "       - Usefulness for the task\n",
    "       - Type of distribution (Gaussian, Logarithmic, Uniform ..)\n",
    "    - For supervised Learning tasks, we identify the target attribute\n",
    "    - We visualize the data\n",
    "    - We study the correlations between attributes\n",
    "    - We study how we would solve the problem manually\n",
    "    - We identify the promising transformations we may want to apply\n",
    "    - We Identify Extra data that would be useful\n",
    "    - We Document what we have learned in report\n",
    "\n",
    "4. Prepare the data for training machine learning algorithms\n",
    "      - We create a copy of the data.\n",
    "      - We write functions for all the data transformations we want to apply: we do this once for reproducibility on test and production data. Packaging functions like this will also allow us to treat preprocessing steps as hyper-parameters.\n",
    "     - We clean the data by fixing or removing outliers, and filling missing values with `0`, mean, median, inference, .. or drop their rows/columns.\n",
    "     - We conduct feature selection: we drop the attributes that provide no useful information for the task\n",
    "     - We conduct feature engineering. Examples of feature engineering:\n",
    "       - Discretize continuous features\n",
    "       - Decompose features (Categorical, datetime, ...)\n",
    "       - Add promissing feature transformations ($log(x)$, $sqrt(x)$, $x^{2}$, ..)\n",
    "       - Aggregate features into promising new features\n",
    "    - We scale the features of interest by standarizing and/or normalize them.\n",
    "\n",
    "5. Ranking the models which performs better and promising results for solving the problems\n",
    "    - If the data set is big, we sample smaller datasets for experimentation.\n",
    "    - We try many models from different categories (`NB`, `Linear regression`, `RF`, `NN`, ..) using standard parameters.\n",
    "    - We measure and compare their performances: for each model, we measure `N`-fold cross validation and capture the mean and standard diviation of the performance.\n",
    "    - We analyze the most significant variable for each algorithm.\n",
    "    - We analyze the types of errors the models make. What data would we use to avoid these errors?\n",
    "    - We perform a quick round of feature selection and engineering.\n",
    "    - We perform one or two more quick iterations of the previous steps.\n",
    "    - We shortlist the top-`3`-to-`5` most performant algorithms that make different types of errors.\n",
    "\n",
    "6. Fine-tuning the hyperparameters of the models for improving thier performance, ensamble them and export a final model for solution to our original problem.\n",
    "   - We should use the whole dataset\n",
    "   - We fine-tune hyper-parameters using cross-validation\n",
    "\n",
    "   - We treat our data transformation choices as hyper-parameters. Unless there are very few hyper-parameters to explore, we should prefer random search to grid search. If training takes a long time, we try out Bayesian Optimization.\n",
    "\n",
    "   - We try ensemble methods. Combining the best models will often produce better results than running them individually.\n",
    "   - Once we are confident about the model, we measure its performance on the test set to estimate its generalization error.\n",
    "\n",
    "7. Presenting our work in easy accessible fashion that adresses the problem.\n",
    "   - We document what we have done\n",
    "   - We create a nice presentation\n",
    "   - We explain why our solution achieves the business objective\n",
    "   - We showcase interesting things we noticed along the way\n",
    "   - We ensure the key findings are easily communicated through beautiful visualization and one-line statements\n",
    "\n",
    "8. Now, Launching, Monitoring and Maintaining our models which provides the solutions to the original problem\n",
    "   - We get our solution ready for production\n",
    "   - We write monitoring code to check our system's performance while running in production and run interval-based checks to alert when it drops.\n",
    "\n",
    "9. The \"slow degradation\" phenomena\n",
    "The models some times tend to rot as data evolves. So,  We should also monitor our inputs quality and then we re-train the model on a regular basis on fresh data such the it work without any gliches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

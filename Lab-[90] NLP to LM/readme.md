NLP




## References


### 2. Word Vector and Language Models

1. [Efficient Estimation of Word Representations in Vector Space](http://arxiv.org/pdf/1301.3781.pdf) (original word2vec paper)
2. [Distributed Representations of Words and Phrases and their Compositionality](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) (negative sampling paper)
3. [GloVe: Global Vectors for Word Representation](http://nlp.stanford.edu/pubs/glove.pdf) (original GloVe paper)
4. [Improving Distributional Similarity with Lessons Learned from Word Embeddings](http://www.aclweb.org/anthology/Q15-1016)
5. [Evaluation methods for unsupervised word embeddings](http://www.aclweb.org/anthology/D15-1036)
6.  [A Latent Variable Model Approach to PMI-based Word Embeddings](http://aclweb.org/anthology/Q16-1028)
7. [Linear Algebraic Structure of Word Senses, with Applications to Polysemy](https://transacl.org/ojs/index.php/tacl/article/viewFile/1346/320)
8. [On the Dimensionality of Word Embedding](https://papers.nips.cc/paper/7368-on-the-dimensionality-of-word-embedding.pdf)

### 1. Transformers

1. [Attention Is All You Need](https://arxiv.org/abs/1706.03762.pdf)
2. [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
3. [Transformer (Google AI blog post)](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html)
4. [Layer Normalization](https://arxiv.org/pdf/1607.06450.pdf)
5. [Image Transformer](https://arxiv.org/pdf/1802.05751.pdf)
6. [Music Transformer: Generating music with long-term structure](https://arxiv.org/pdf/1809.04281.pdf)
7. [Jurafsky and Martin Chapter 10 (Transformers and Large Language Models)](https://web.stanford.edu/~jurafsky/slpdraft/10.pdf)
7.

# Theoretical Machine Learning

- Understanding of machine learning algorithms - model, objective or loss function, optimization algorithm and evaluation criteria.
- Parameter tuning of  machine learning algorithms based on the outcome of experiments - what steps to take in case of underfitting and overfitting and to improve the performance of the model on the unseen dataset i.e model will befome generalized well.
- Develope proper understanding of  choosing among multiple algorithms for a given task.
- How and where to use the unsupervised learning techniques, we have to develop proper understanding of it.

### Learning Schedules

WEEK 1	Introduction; Unsupervised Learning - Representation learning - PCA
Lectures

1. Introduction to machine learning
   https://www.youtube.com/watch?v=KMcUe7GQnf0
2. Paradigms of machine learning
   https://www.youtube.com/watch?v=ipjggYk7zXs
3. Representation Learning: Part 1
   https://www.youtube.com/watch?v=1V_M4JxygGk
4. Representation Learning: Part 2
   https://www.youtube.com/watch?v=mU6CzvuUM00
5. Representation Learning: Part 3
   https://www.youtube.com/watch?v=t0bA3rsZ6qM
6. Principal component analysis: Part 1
   https://www.youtube.com/watch?v=_GOADM-SdKU

WEEK 2	Unsupervised Learning - Representation learning - Kernel PCA

7. Principal component analysis: Part 2
   https://www.youtube.com/watch?v=o__dWBLqPhQ
8. Issues with PCA
   https://www.youtube.com/watch?v=sgU4zbO-W4M
9. Time-complexity issue with PCA
   https://www.youtube.com/watch?v=pwpDf2_Pytk
10. Feature Transformation
    https://www.youtube.com/watch?v=zcxnCyVSh70
11. Kernel PCA
    https://www.youtube.com/watch?v=K46tdjqxM0w
12. Kernel Functions
    https://www.youtube.com/watch?v=G6rMGLhw3IQ

WEEK 3	Unsupervised Learning - Clustering - K-means/Kernel K-means

13. Introduction to Clustering
    https://www.youtube.com/watch?v=A3UNtCuMm7Y
14. K-means Clustering (Lloyd's algorithm)
    https://www.youtube.com/watch?v=QrXQ5cMzphA
15. Convergence of K-means algorithm
    https://www.youtube.com/watch?v=5geXmawaImk
16. Nature of clusters produced by K-means
    https://www.youtube.com/watch?v=EY03QHaaSBY
17. Initialization of centroids, K-means++
    https://www.youtube.com/watch?v=Cbrdtxq6bdk
18. Choice of K
    https://www.youtube.com/watch?v=4-ycWgdMXD4

WEEK 4	Unsupervised Learning - Estimation - Recap of MLE + Bayesian estimation, Gaussian Mixture Model - EM algorithm.

19. Introduction to Estimation
    https://www.youtube.com/watch?v=382yNz5LoX0
20. Maximum Likelihood Estimation
    https://www.youtube.com/watch?v=9dQSEn0ooTc
21. Bayesian estimation
    https://www.youtube.com/watch?v=ZnkRbtZLPm4
22. Gaussian Mixture Models
    https://www.youtube.com/watch?v=dyRTVmtML-U
23. Likelihood of GMM
    https://www.youtube.com/watch?v=a-VVrP11ZIo
24. Convex functions and Jensen's inequality
    https://www.youtube.com/watch?v=4s0aNldT02Y

WEEK 5	Supervised Learning - Regression - Least Squares; Bayesian view


25. Estimating the parameters
    https://www.youtube.com/watch?v=idWmaE39OIk
26. EM algorithm
    https://www.youtube.com/watch?v=1jSonYih_sM
27. Supervised Learning
    https://www.youtube.com/watch?v=AIKTk9KtPJ0
28. Linear Regression
    https://www.youtube.com/watch?v=RkcCmmN0TY4
29. Optimizing the error function
    https://www.youtube.com/watch?v=JQPLz5YhjaM
30. Geometric interpretation of linear regression
    https://www.youtube.com/watch?v=SGbelq087Qs

WEEK 6	Supervised Learning - Regression - Ridge/LASSO

31. Gradient descent
    https://www.youtube.com/watch?v=vS1LK8xoM4g
32. Kernel regression
    https://www.youtube.com/watch?v=u9ir3yQynpE
33. Probabilistic view of linear regression
    https://www.youtube.com/watch?v=gLGQokSrtDI
34. Goodness of Maximum Likelihood Estimator for linear regression
    https://www.youtube.com/watch?v=_CNCiGfwdQs
35. Cross-validation for minimizing MSE
    https://www.youtube.com/watch?v=_hmPiYKlRTQ
36. Bayesian Modeling for linear regression
    https://www.youtube.com/watch?v=DG7KvatwL2Q\

WEEK 7	Supervised Learning - Classification - K-NN, Decision tree


37. Ridge regression
    https://www.youtube.com/watch?v=dMB1c5NADnE
38. Relation between solution of linear regression and ridge regression
    https://www.youtube.com/watch?v=rCfjaEYxaC8
39. Relation between solution of linear regression and Lasso regression
    https://www.youtube.com/watch?v=f9KWAixPUCc
40. Characteristics of Lasso regression
    https://www.youtube.com/watch?v=79eeNk7InHk
41. Introduction to Binary Classification
    https://www.youtube.com/watch?v=_w9irUy_8Cs
42. K-Nearest Neighbours
    https://www.youtube.com/watch?v=H-Y_A7HvBqk

WEEK 8	Supervised Learning - Classification - Generative Models - Naive Bayes


43. Introduction to Decision Trees
    https://www.youtube.com/watch?v=gXbAJGd8fO0
44. Decision Tree Algorithm
    https://www.youtube.com/watch?v=5rnu6Hvbt8I
45. Generative and Discriminative Models
    https://www.youtube.com/watch?v=gwa47ZzhYno
46. Generative model-based algorithm
    https://www.youtube.com/watch?v=tna8wxoasss
47. Naive Bayes algorithm
    https://www.youtube.com/watch?v=VKqGflpKG_A
48. Gaussian naive Bayes
    https://www.youtube.com/watch?v=oTMYU7hC2bw

WEEK 9	Discriminative Models - Perceptron; Logistic Regression


49. Pitfalls of naive Bayes algorithm
    https://www.youtube.com/watch?v=RuE8SQajgxY
50. Decision function of naive Bayes
    https://www.youtube.com/watch?v=ADXQaTI0Lpo
51. Alternate generative model-based algorithm
    https://www.youtube.com/watch?v=GdYLuJqHZAc
52. Perceptron Learning Algorithm
    https://www.youtube.com/watch?v=G7tYdl0Osf4
53. Understanding Perceptron Update Rule
    https://www.youtube.com/watch?v=FMRpmR9HNtY
54. Sigmoid function for modeling class probabilities
    https://www.youtube.com/watch?v=udFWtBLJUvA

WEEK 10	Support Vector Machines

55. Logistic Regression
    https://www.youtube.com/watch?v=bb4yn4RssLs
56. Proof of convergence of Perceptron Algorithm
    https://www.youtube.com/watch?v=fHDouTKwfXw
57. Perceptrons and Margin
    https://www.youtube.com/watch?v=-guLBqucS_I
58. Maximum margin: Formulation
    https://www.youtube.com/watch?v=ZzWFdt_6KLA
59. Constrained Optimization
    https://www.youtube.com/watch?v=7Th2YgPMnk0
60. Formulating the Dual Problem
    https://www.youtube.com/watch?v=85BxDKkiK4c

WEEK 11	Ensemble methods - Bagging and Boosting (Adaboost)


61. Support Vector Machine
    https://www.youtube.com/watch?v=2LnQ2r7Q3-0
62. Soft Margin SVM
    https://www.youtube.com/watch?v=leolYGmaFLM
63. Dual formulation for Soft Margin SVM
    https://www.youtube.com/watch?v=MZzp4OP8GgQ
64. Complementary slackness conditions for soft-margin SVM
    https://www.youtube.com/watch?v=jthjk2nboDM
65. Summary for soft-margin SVM
    https://www.youtube.com/watch?v=jbcaJ_kn3CQ
66. Overfitting and underfitting
    https://www.youtube.com/watch?v=VcrPtcJWvDE

WEEK 12	Artificial Neural networks: Multiclass classification.

67. Bagging
    https://www.youtube.com/watch?v=OXTu2vrsTjY
68. Boosting
    https://www.youtube.com/watch?v=-B534pLpnhk
69. Classification Loss functions
    https://www.youtube.com/watch?v=1ok_K5EohoU
70. SVM and Logistic Loss
    https://www.youtube.com/watch?v=tXVelGBsIPI
71. Perceptron and Boosting Loss
    https://www.youtube.com/watch?v=ZAuZqOM-skQ
72. Neural Networks
    https://www.youtube.com/watch?v=Y6CNz0wRWpI
73. Computing parameters of a neural network
    https://www.youtube.com/watch?v=LctgFHD_RN4
74. Summary of the course and future directions
    https://www.youtube.com/watch?v=06PP-3xUCs0
    


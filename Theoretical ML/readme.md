# Theoretical Machine Learning

-  Understanding of machine learning algorithms - model, objective or loss function, optimization algorithm and evaluation criteria.
- Parameter tuning of  machine learning algorithms based on the outcome of experiments - what steps to take in case of underfitting and overfitting and to improve the performance of the model on the unseen dataset i.e model will befome generalized well.
- Develope proper understanding of  choosing among multiple algorithms for a given task.
- How and where to use the unsupervised learning techniques, we have to develop proper understanding of it.
### Learning Schedules
WEEK 1	Introduction; Unsupervised Learning - Representation learning - PCA
Lectures 

WEEK 2	Unsupervised Learning - Representation learning - Kernel PCA


WEEK 3	Unsupervised Learning - Clustering - K-means/Kernel K-means
WEEK 4	Unsupervised Learning - Estimation - Recap of MLE + Bayesian estimation, Gaussian Mixture Model - EM algorithm.
WEEK 5	Supervised Learning - Regression - Least Squares; Bayesian view
WEEK 6	Supervised Learning - Regression - Ridge/LASSO
WEEK 7	Supervised Learning - Classification - K-NN, Decision tree
WEEK 8	Supervised Learning - Classification - Generative Models - Naive Bayes
WEEK 9	Discriminative Models - Perceptron; Logistic Regression
WEEK 10	Support Vector Machines
WEEK 11	Ensemble methods - Bagging and Boosting (Adaboost)
WEEK 12	Artificial Neural networks: Multiclass classification.


## Lectures
Introduction to machine learning
https://www.youtube.com/watch?v=KMcUe7GQnf0
Paradigms of machine learning
https://www.youtube.com/watch?v=ipjggYk7zXs
Representation Learning: Part 1
https://www.youtube.com/watch?v=1V_M4JxygGk
Representation Learning: Part 2
https://www.youtube.com/watch?v=mU6CzvuUM00
Representation Learning: Part 3
https://www.youtube.com/watch?v=t0bA3rsZ6qM
Principal component analysis: Part 1
https://www.youtube.com/watch?v=_GOADM-SdKU
Principal component analysis: Part 2
https://www.youtube.com/watch?v=o__dWBLqPhQ
Issues with PCA
https://www.youtube.com/watch?v=sgU4zbO-W4M
Time-complexity issue with PCA
https://www.youtube.com/watch?v=pwpDf2_Pytk
Feature Transformation
https://www.youtube.com/watch?v=zcxnCyVSh70
Kernel PCA
https://www.youtube.com/watch?v=K46tdjqxM0w
Kernel Functions
https://www.youtube.com/watch?v=G6rMGLhw3IQ
Introduction to Clustering
https://www.youtube.com/watch?v=A3UNtCuMm7Y
K-means Clustering (Lloyd's algorithm)
https://www.youtube.com/watch?v=QrXQ5cMzphA
Convergence of K-means algorithm
https://www.youtube.com/watch?v=5geXmawaImk
Nature of clusters produced by K-means
https://www.youtube.com/watch?v=EY03QHaaSBY
Initialization of centroids, K-means++
https://www.youtube.com/watch?v=Cbrdtxq6bdk
Choice of K
https://www.youtube.com/watch?v=4-ycWgdMXD4
Introduction to Estimation
https://www.youtube.com/watch?v=382yNz5LoX0
Maximum Likelihood Estimation
https://www.youtube.com/watch?v=9dQSEn0ooTc
Bayesian estimation
https://www.youtube.com/watch?v=ZnkRbtZLPm4
Gaussian Mixture Models
https://www.youtube.com/watch?v=dyRTVmtML-U
Likelihood of GMM
https://www.youtube.com/watch?v=a-VVrP11ZIo
Convex functions and Jensen's inequality
https://www.youtube.com/watch?v=4s0aNldT02Y
Estimating the parameters
https://www.youtube.com/watch?v=idWmaE39OIk
EM algorithm
https://www.youtube.com/watch?v=1jSonYih_sM
Supervised Learning
https://www.youtube.com/watch?v=AIKTk9KtPJ0
Linear Regression
https://www.youtube.com/watch?v=RkcCmmN0TY4
Optimizing the error function
https://www.youtube.com/watch?v=JQPLz5YhjaM
Geometric interpretation of linear regression
https://www.youtube.com/watch?v=SGbelq087Qs
Gradient descent
https://www.youtube.com/watch?v=vS1LK8xoM4g
Kernel regression
https://www.youtube.com/watch?v=u9ir3yQynpE
Probabilistic view of linear regression
https://www.youtube.com/watch?v=gLGQokSrtDI
Goodness of Maximum Likelihood Estimator for linear regression
https://www.youtube.com/watch?v=_CNCiGfwdQs
Cross-validation for minimizing MSE
https://www.youtube.com/watch?v=_hmPiYKlRTQ
Bayesian Modeling for linear regression
https://www.youtube.com/watch?v=DG7KvatwL2Q
Ridge regression
https://www.youtube.com/watch?v=dMB1c5NADnE
Relation between solution of linear regression and ridge regression
https://www.youtube.com/watch?v=rCfjaEYxaC8
Relation between solution of linear regression and Lasso regression
https://www.youtube.com/watch?v=f9KWAixPUCc
Characteristics of Lasso regression
https://www.youtube.com/watch?v=79eeNk7InHk
Introduction to Binary Classification
https://www.youtube.com/watch?v=_w9irUy_8Cs
K-Nearest Neighbours
https://www.youtube.com/watch?v=H-Y_A7HvBqk
Introduction to Decision Trees
https://www.youtube.com/watch?v=gXbAJGd8fO0
Decision Tree Algorithm
https://www.youtube.com/watch?v=5rnu6Hvbt8I
Generative and Discriminative Models
https://www.youtube.com/watch?v=gwa47ZzhYno
Generative model-based algorithm
https://www.youtube.com/watch?v=tna8wxoasss
Naive Bayes algorithm
https://www.youtube.com/watch?v=VKqGflpKG_A
Gaussian naive Bayes
https://www.youtube.com/watch?v=oTMYU7hC2bw
Pitfalls of naive Bayes algorithm
https://www.youtube.com/watch?v=RuE8SQajgxY
Decision function of naive Bayes
https://www.youtube.com/watch?v=ADXQaTI0Lpo
Alternate generative model-based algorithm
https://www.youtube.com/watch?v=GdYLuJqHZAc
Perceptron Learning Algorithm
https://www.youtube.com/watch?v=G7tYdl0Osf4
Understanding Perceptron Update Rule
https://www.youtube.com/watch?v=FMRpmR9HNtY
Sigmoid function for modeling class probabilities
https://www.youtube.com/watch?v=udFWtBLJUvA
Logistic Regression
https://www.youtube.com/watch?v=bb4yn4RssLs
Proof of convergence of Perceptron Algorithm
https://www.youtube.com/watch?v=fHDouTKwfXw
Perceptrons and Margin
https://www.youtube.com/watch?v=-guLBqucS_I
Maximum margin: Formulation
https://www.youtube.com/watch?v=ZzWFdt_6KLA
Constrained Optimization
https://www.youtube.com/watch?v=7Th2YgPMnk0
Formulating the Dual Problem
https://www.youtube.com/watch?v=85BxDKkiK4c
Support Vector Machine
https://www.youtube.com/watch?v=2LnQ2r7Q3-0
Soft Margin SVM
https://www.youtube.com/watch?v=leolYGmaFLM
Dual formulation for Soft Margin SVM
https://www.youtube.com/watch?v=MZzp4OP8GgQ
Complementary slackness conditions for soft-margin SVM
https://www.youtube.com/watch?v=jthjk2nboDM
Summary for soft-margin SVM
https://www.youtube.com/watch?v=jbcaJ_kn3CQ
Overfitting and underfitting
https://www.youtube.com/watch?v=VcrPtcJWvDE
Bagging
https://www.youtube.com/watch?v=OXTu2vrsTjY
Boosting
https://www.youtube.com/watch?v=-B534pLpnhk
Classification Loss functions
https://www.youtube.com/watch?v=1ok_K5EohoU
SVM and Logistic Loss
https://www.youtube.com/watch?v=tXVelGBsIPI
Perceptron and Boosting Loss
https://www.youtube.com/watch?v=ZAuZqOM-skQ
Neural Networks
https://www.youtube.com/watch?v=Y6CNz0wRWpI
Computing parameters of a neural network
https://www.youtube.com/watch?v=LctgFHD_RN4
Summary of the course and future directions
https://www.youtube.com/watch?v=06PP-3xUCs0